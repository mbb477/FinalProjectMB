<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Melanie Beebe">

<title>Modeling of the Diabetes Health Indicators Set</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Modeling of the Diabetes Health Indicators Set</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Melanie Beebe </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The goal of this document is to explain the process and results of model fitting for prediction of diabetes using the Diabetes Health Indicators Dataset from 2015. This data set is a subset of data taken from the Behavioral Risk Factor Surveillance System (BRFSS) run by the Centers for Disease Control and Prevention (CDC). This data is obtained through a health-related telephone survey that is conducted every year. The Diabetes Health Indicators Dataset contains 22 variables and 253,680 observations.</p>
<p>For modeling, 3 candidate models will be fit using logistic regression, classification tree and random forest. This will be done using the caret package. Various options are available for measuring performance of the model. Accuracy is the most common measure used and the default in caret for classification models, but log loss will be used here for all models due to the class imbalance in this data set.</p>
<p>Log loss takes into account the uncertainty of predictions by penalizing models more heavily for incorrect predictions, particularly incorrect confident predictions. This means that the further the prediction probability is from the actual value, the higher the log loss is. So a model with a lower log loss is more desirable. Log loss is preferred for this data because it is imbalanced, with 86% of the observations being non-diabetics. If accuracy is used, the models predictions might be more biased towards the more frequent class and as a result could have high prediction accuracy for the more frequent class, but fail to identify many minority class cases. By penalizing models for incorrect predictions, log loss allows a more balanced view of performance for the classes.</p>
</section>
<section id="model-fitting" class="level1">
<h1>Model Fitting</h1>
<p>To fit the models, the data needs to be imported using read_csv from tidyverse. This csv file was created from EDA after assigning meaningful labels to the category levels. Since data classes are not preserved when writing a csv file, the categories need to be converted to factors again.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#load libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">#read in data</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>diabetes1 <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"diabetes.csv"</span>, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#convert to factors</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>diabetes1  <span class="ot">&lt;-</span> diabetes1 <span class="sc">|&gt;</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Diabetes_binary =</span> <span class="fu">factor</span>(Diabetes_binary, <span class="at">levels =</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                                    <span class="fu">c</span>(<span class="st">"Non_Diabetic"</span>, <span class="st">"Prediabetic_Diabetic"</span>)),</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">Age =</span> <span class="fu">factor</span>(Age,<span class="at">ordered =</span> <span class="cn">TRUE</span>, <span class="at">levels =</span> </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">c</span>(<span class="st">"Age_18to24"</span>, <span class="st">"Age_25to29"</span>, </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Age_30to34"</span>, <span class="st">"Age_35to39"</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Age_40to44"</span>, <span class="st">"Age_45to49"</span>, </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Age_50to54"</span>, <span class="st">"Age_55to59"</span>, </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Age_60to64"</span>, <span class="st">"Age_65to69"</span>, </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Age_70to74"</span>, <span class="st">"Age_75to79"</span>, </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                          <span class="st">"Age_80_or_above"</span>)),</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">Education =</span> <span class="fu">factor</span>(Education, <span class="at">ordered =</span> <span class="cn">TRUE</span>, <span class="at">levels =</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                              <span class="fu">c</span>(<span class="st">"No_School"</span>, <span class="st">"Primary_and_Middle"</span>,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"Some_High_School"</span>, <span class="st">"Graduated_High_School"</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"Some_College"</span>, <span class="st">"Graduated_College"</span>)),</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>         <span class="at">Sex =</span> <span class="fu">as.factor</span>(Sex),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>         <span class="at">Income =</span> <span class="fu">factor</span>(Income, <span class="at">ordered =</span> <span class="cn">TRUE</span>, <span class="at">levels =</span> </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">c</span>(<span class="st">"Less_than_10K"</span>,</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_10K_to_under_15K"</span>,</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_15K_to_under_20K"</span>,</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_20K_to_under_25K"</span>, </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_25K_to_under_35K"</span>,</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_35K_to_under_50K"</span>, </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_50K_to_under_75K"</span>,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"From_75K_or_more"</span>)),</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>         <span class="at">DiffWalk =</span> <span class="fu">as.factor</span>(DiffWalk),</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>         <span class="at">NoDocbcCost =</span> <span class="fu">as.factor</span>(NoDocbcCost),</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>         <span class="at">AnyHealthcare =</span> <span class="fu">as.factor</span>(AnyHealthcare),</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>         <span class="at">HvyAlcoholConsump =</span> <span class="fu">as.factor</span>(HvyAlcoholConsump),</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>         <span class="at">Smoker =</span> <span class="fu">as.factor</span>(Smoker),</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>         <span class="at">CholCheck =</span> <span class="fu">as.factor</span>(CholCheck),</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>         <span class="at">PhysActivity =</span> <span class="fu">as.factor</span>(PhysActivity),</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>         <span class="at">HeartDiseaseorAttack =</span> <span class="fu">as.factor</span>(HeartDiseaseorAttack),</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>         <span class="at">Stroke =</span> <span class="fu">as.factor</span>(Stroke),</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>         <span class="at">HighBP =</span> <span class="fu">as.factor</span>(HighBP),</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>         <span class="at">HighChol =</span> <span class="fu">as.factor</span>(HighChol),</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>         <span class="at">Fruits =</span> <span class="fu">as.factor</span>(Fruits),</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>         <span class="at">Veggies =</span> <span class="fu">as.factor</span>(Veggies),</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>         <span class="at">GenHlth =</span> <span class="fu">factor</span>(GenHlth, <span class="at">ordered =</span> <span class="cn">TRUE</span>, <span class="at">levels =</span> </span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">c</span>(<span class="st">"Excellent"</span>, <span class="st">"Very_Good"</span>, <span class="st">"Good"</span>, </span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>                               <span class="st">"Fair"</span>, <span class="st">"Poor"</span>)))</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>diabetes1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 253,680 × 22
   Diabetes_binary      HighBP HighChol CholCheck   BMI Smoker Stroke
   &lt;fct&gt;                &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; 
 1 Non_Diabetic         Yes    Yes      Yes          40 Yes    No    
 2 Non_Diabetic         No     No       No           25 Yes    No    
 3 Non_Diabetic         Yes    Yes      Yes          28 No     No    
 4 Non_Diabetic         Yes    No       Yes          27 No     No    
 5 Non_Diabetic         Yes    Yes      Yes          24 No     No    
 6 Non_Diabetic         Yes    Yes      Yes          25 Yes    No    
 7 Non_Diabetic         Yes    No       Yes          30 Yes    No    
 8 Non_Diabetic         Yes    Yes      Yes          25 Yes    No    
 9 Prediabetic_Diabetic Yes    Yes      Yes          30 Yes    No    
10 Non_Diabetic         No     No       Yes          24 No     No    
# ℹ 253,670 more rows
# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,
#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,
#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;ord&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,
#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;ord&gt;, Education &lt;ord&gt;, Income &lt;ord&gt;</code></pre>
</div>
</div>
<p>The models that will be tested are the following:</p>
<ol type="1">
<li>Full model with all 21 predictor variables</li>
<li>Model with 13 predictor variables as identified in EDA</li>
<li>Model with 8 predictor variables, including Age, BMI, HighBP, HighChol, Income , HeartDiseaseorAttack, PhysHlth and GenHlth variables.</li>
</ol>
<p>The data with all 21 predictor variables will be used as a reference point since it is not a lot of variables. The second model was determined using EDA and is discussed in that document. The third model contains 4 variables known scientifically to be associated with diabetes risk, Age, BMI, HighBP and HighChol. In addition the Income, HeartDiseaseorAttack, PhysHlth and GenHlth variables will be included.</p>
<p>The next step is to create new data sets for each of the models and split the data into testing and training sets.</p>
<section id="model-1" class="level3">
<h3 class="anchored" data-anchor-id="model-1">Model 1</h3>
<p>Data will be split 70/30 for training and testing. Since model 1 includes all variables, the imported data above will be used. The createPartition() function from caret is used as it tries to maintain the class distribution (for the Diabetes_binary response variable) for both sets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#set seed for reproducibility</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Partition data</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>trainIndex <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(diabetes1<span class="sc">$</span>Diabetes_binary, </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">p =</span> <span class="fl">0.7</span>, </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Create training set</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>diabetesTrain1 <span class="ot">&lt;-</span> diabetes1[trainIndex, ]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Create test set</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>diabetesTest1 <span class="ot">&lt;-</span> diabetes1[<span class="sc">-</span>trainIndex, ]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>diabetesTrain1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 177,577 × 22
   Diabetes_binary      HighBP HighChol CholCheck   BMI Smoker Stroke
   &lt;fct&gt;                &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; 
 1 Non_Diabetic         Yes    Yes      Yes          40 Yes    No    
 2 Non_Diabetic         No     No       No           25 Yes    No    
 3 Non_Diabetic         Yes    No       Yes          27 No     No    
 4 Non_Diabetic         Yes    Yes      Yes          24 No     No    
 5 Non_Diabetic         Yes    Yes      Yes          25 Yes    No    
 6 Non_Diabetic         Yes    No       Yes          30 Yes    No    
 7 Non_Diabetic         Yes    Yes      Yes          25 Yes    No    
 8 Prediabetic_Diabetic Yes    Yes      Yes          30 Yes    No    
 9 Prediabetic_Diabetic No     No       Yes          25 Yes    No    
10 Non_Diabetic         Yes    Yes      Yes          34 Yes    No    
# ℹ 177,567 more rows
# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,
#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,
#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;ord&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,
#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;ord&gt;, Education &lt;ord&gt;, Income &lt;ord&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>diabetesTest1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 22
   Diabetes_binary      HighBP HighChol CholCheck   BMI Smoker Stroke
   &lt;fct&gt;                &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; 
 1 Non_Diabetic         Yes    Yes      Yes          28 No     No    
 2 Non_Diabetic         No     No       Yes          24 No     No    
 3 Non_Diabetic         No     No       Yes          26 Yes    No    
 4 Non_Diabetic         No     Yes      Yes          33 Yes    Yes   
 5 Non_Diabetic         Yes    No       Yes          33 No     No    
 6 Non_Diabetic         No     No       No           23 No     No    
 7 Non_Diabetic         Yes    Yes      Yes          28 Yes    No    
 8 Prediabetic_Diabetic Yes    Yes      Yes          37 Yes    Yes   
 9 Prediabetic_Diabetic Yes    Yes      Yes          28 Yes    No    
10 Non_Diabetic         Yes    No       Yes          26 No     No    
# ℹ 76,093 more rows
# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,
#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,
#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;ord&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,
#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;ord&gt;, Education &lt;ord&gt;, Income &lt;ord&gt;</code></pre>
</div>
</div>
</section>
<section id="model-2" class="level3">
<h3 class="anchored" data-anchor-id="model-2">Model 2</h3>
<p>For model 2, we can use the training and test sets above for model 1 and remove the variables not used for this model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>diabetesTrain2 <span class="ot">&lt;-</span> diabetesTrain1 <span class="sc">|&gt;</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>CholCheck,<span class="sc">-</span>Smoker, <span class="sc">-</span>Fruits, <span class="sc">-</span>Veggies, <span class="sc">-</span>AnyHealthcare, <span class="sc">-</span>NoDocbcCost,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>         <span class="sc">-</span>Sex, <span class="sc">-</span>Education)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>diabetesTest2 <span class="ot">&lt;-</span> diabetesTest1 <span class="sc">|&gt;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>CholCheck,<span class="sc">-</span>Smoker, <span class="sc">-</span>Fruits, <span class="sc">-</span>Veggies, <span class="sc">-</span>AnyHealthcare, <span class="sc">-</span>NoDocbcCost,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>         <span class="sc">-</span>Sex, <span class="sc">-</span>Education)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>diabetesTrain2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 177,577 × 14
   Diabetes_binary      HighBP HighChol   BMI Stroke HeartDiseaseorAttack
   &lt;fct&gt;                &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;               
 1 Non_Diabetic         Yes    Yes         40 No     No                  
 2 Non_Diabetic         No     No          25 No     No                  
 3 Non_Diabetic         Yes    No          27 No     No                  
 4 Non_Diabetic         Yes    Yes         24 No     No                  
 5 Non_Diabetic         Yes    Yes         25 No     No                  
 6 Non_Diabetic         Yes    No          30 No     No                  
 7 Non_Diabetic         Yes    Yes         25 No     No                  
 8 Prediabetic_Diabetic Yes    Yes         30 No     Yes                 
 9 Prediabetic_Diabetic No     No          25 No     No                  
10 Non_Diabetic         Yes    Yes         34 No     No                  
# ℹ 177,567 more rows
# ℹ 8 more variables: PhysActivity &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;,
#   GenHlth &lt;ord&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;, DiffWalk &lt;fct&gt;, Age &lt;ord&gt;,
#   Income &lt;ord&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>diabetesTest2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 14
   Diabetes_binary      HighBP HighChol   BMI Stroke HeartDiseaseorAttack
   &lt;fct&gt;                &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;               
 1 Non_Diabetic         Yes    Yes         28 No     No                  
 2 Non_Diabetic         No     No          24 No     No                  
 3 Non_Diabetic         No     No          26 No     No                  
 4 Non_Diabetic         No     Yes         33 Yes    No                  
 5 Non_Diabetic         Yes    No          33 No     No                  
 6 Non_Diabetic         No     No          23 No     No                  
 7 Non_Diabetic         Yes    Yes         28 No     No                  
 8 Prediabetic_Diabetic Yes    Yes         37 Yes    Yes                 
 9 Prediabetic_Diabetic Yes    Yes         28 No     Yes                 
10 Non_Diabetic         Yes    No          26 No     No                  
# ℹ 76,093 more rows
# ℹ 8 more variables: PhysActivity &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;,
#   GenHlth &lt;ord&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;, DiffWalk &lt;fct&gt;, Age &lt;ord&gt;,
#   Income &lt;ord&gt;</code></pre>
</div>
</div>
</section>
<section id="model-3" class="level3">
<h3 class="anchored" data-anchor-id="model-3">Model 3</h3>
<p>Similar to what was done for model 2, the training and test sets for model 3 can be obtained by removing the appropriate columns from model 2’s training and test sets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>diabetesTrain3 <span class="ot">&lt;-</span> diabetesTrain2 <span class="sc">|&gt;</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>Stroke,<span class="sc">-</span>MentHlth, <span class="sc">-</span>HvyAlcoholConsump, <span class="sc">-</span>DiffWalk, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>         <span class="sc">-</span>PhysActivity)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>diabetesTest3 <span class="ot">&lt;-</span> diabetesTest2 <span class="sc">|&gt;</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>Stroke,<span class="sc">-</span>MentHlth, <span class="sc">-</span>HvyAlcoholConsump, <span class="sc">-</span>DiffWalk, </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>         <span class="sc">-</span>PhysActivity)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>diabetesTrain3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 177,577 × 9
   Diabetes_binary   HighBP HighChol   BMI HeartDiseaseorAttack GenHlth PhysHlth
   &lt;fct&gt;             &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                &lt;ord&gt;      &lt;dbl&gt;
 1 Non_Diabetic      Yes    Yes         40 No                   Poor          15
 2 Non_Diabetic      No     No          25 No                   Good           0
 3 Non_Diabetic      Yes    No          27 No                   Very_G…        0
 4 Non_Diabetic      Yes    Yes         24 No                   Very_G…        0
 5 Non_Diabetic      Yes    Yes         25 No                   Very_G…        2
 6 Non_Diabetic      Yes    No          30 No                   Good          14
 7 Non_Diabetic      Yes    Yes         25 No                   Good           0
 8 Prediabetic_Diab… Yes    Yes         30 Yes                  Poor          30
 9 Prediabetic_Diab… No     No          25 No                   Good           0
10 Non_Diabetic      Yes    Yes         34 No                   Good          30
# ℹ 177,567 more rows
# ℹ 2 more variables: Age &lt;ord&gt;, Income &lt;ord&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>diabetesTest3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 9
   Diabetes_binary   HighBP HighChol   BMI HeartDiseaseorAttack GenHlth PhysHlth
   &lt;fct&gt;             &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                &lt;ord&gt;      &lt;dbl&gt;
 1 Non_Diabetic      Yes    Yes         28 No                   Poor          30
 2 Non_Diabetic      No     No          24 No                   Very_G…        0
 3 Non_Diabetic      No     No          26 No                   Good          15
 4 Non_Diabetic      No     Yes         33 No                   Fair          28
 5 Non_Diabetic      Yes    No          33 No                   Very_G…        0
 6 Non_Diabetic      No     No          23 No                   Very_G…        0
 7 Non_Diabetic      Yes    Yes         28 No                   Good           0
 8 Prediabetic_Diab… Yes    Yes         37 Yes                  Poor           0
 9 Prediabetic_Diab… Yes    Yes         28 Yes                  Fair           0
10 Non_Diabetic      Yes    No          26 No                   Very_G…        0
# ℹ 76,093 more rows
# ℹ 2 more variables: Age &lt;ord&gt;, Income &lt;ord&gt;</code></pre>
</div>
</div>
<p>Now that the training and test sets have been created, some models can be fit.</p>
</section>
<section id="logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h2>
<p>The three models will first be fit using logistic regression. Simply stated, logistic regression calculates the probability of an event occurring based on a data set and uses this information for classification. The event is binary, so refers to yes/no or success/failure. Logistic regression is a generalized linear model that works by linking the response to a function linear in parameters using the logit function, which is the log odds of the event occurring. Since the goal is to use the Diabetes Health Indicators Dataset to predict whether an individual has prediabetes/diabetes or not, logistic regression is appropriate to use.</p>
<p>For fitting logistic regression in caret, we need to specify the method as glm, although there are other options available. Since our response is binary, the family is “binomial”. Since we want to use log loss, we need to specify this as the metric in train() as well as in the trainControl() using summaryFunction (mnLogLoss). Since log loss uses predicted probabilities to evaluate model performance, classProbs needs to be set at TRUE. For the model fits presented here, trainControl will use cross validation as the method (“cv”) and 5 folds (number).</p>
<p>The fit for model 1 with all 21 variables is shown below. The log loss for the fit is 0.317.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run logistic regression on Model 1</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>logRegFit_M1 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain1,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"glm"</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss))</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>logRegFit_M1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized Linear Model 

177577 samples
    21 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss  
  0.3168564</code></pre>
</div>
</div>
<p>The summary for model 1 fit is below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logRegFit_M1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
NULL

Coefficients:
                             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                -5.8075675  0.1061653 -54.703  &lt; 2e-16 ***
HighBPYes                   0.7236103  0.0176443  41.011  &lt; 2e-16 ***
HighCholYes                 0.5292785  0.0163079  32.455  &lt; 2e-16 ***
CholCheckYes                1.2553484  0.0827403  15.172  &lt; 2e-16 ***
BMI                         0.0576228  0.0010903  52.850  &lt; 2e-16 ***
SmokerYes                  -0.0363594  0.0159091  -2.285 0.022287 *  
StrokeYes                   0.1428743  0.0298347   4.789 1.68e-06 ***
HeartDiseaseorAttackYes     0.2494557  0.0212568  11.735  &lt; 2e-16 ***
PhysActivityYes            -0.0570992  0.0172378  -3.312 0.000925 ***
FruitsOne_or_more_per_day  -0.0316766  0.0164129  -1.930 0.053609 .  
VeggiesOne_or_more_per_day -0.0403626  0.0190000  -2.124 0.033641 *  
HvyAlcoholConsumpYes       -0.7936119  0.0466087 -17.027  &lt; 2e-16 ***
AnyHealthcareYes            0.0597127  0.0400401   1.491 0.135877    
NoDocbcCostYes             -0.0039970  0.0275594  -0.145 0.884685    
GenHlth.L                   1.6484010  0.0349706  47.137  &lt; 2e-16 ***
GenHlth.Q                  -0.3692101  0.0264086 -13.981  &lt; 2e-16 ***
GenHlth.C                  -0.0651716  0.0199671  -3.264 0.001099 ** 
`GenHlth^4`                 0.0144172  0.0148045   0.974 0.330139    
MentHlth                   -0.0026657  0.0010153  -2.625 0.008653 ** 
PhysHlth                   -0.0034423  0.0009638  -3.572 0.000355 ***
DiffWalkYes                 0.1361700  0.0202681   6.718 1.84e-11 ***
SexMale                     0.2724640  0.0161617  16.859  &lt; 2e-16 ***
Age.L                       2.3052029  0.0809772  28.467  &lt; 2e-16 ***
Age.Q                      -0.7731608  0.0761771 -10.150  &lt; 2e-16 ***
Age.C                      -0.2258799  0.0707002  -3.195 0.001399 ** 
`Age^4`                    -0.0505754  0.0674966  -0.749 0.453675    
`Age^5`                    -0.1626783  0.0648937  -2.507 0.012181 *  
`Age^6`                     0.0839011  0.0608445   1.379 0.167912    
`Age^7`                     0.0010880  0.0557622   0.020 0.984433    
`Age^8`                     0.0143805  0.0498648   0.288 0.773049    
`Age^9`                    -0.0064350  0.0436131  -0.148 0.882701    
`Age^10`                   -0.0904905  0.0379455  -2.385 0.017091 *  
`Age^11`                    0.0624109  0.0333952   1.869 0.061642 .  
`Age^12`                    0.0261874  0.0284193   0.921 0.356807    
Education.L                -0.1459432  0.1434671  -1.017 0.309030    
Education.Q                 0.0029214  0.1305425   0.022 0.982146    
Education.C                 0.0126293  0.0925402   0.136 0.891447    
`Education^4`              -0.0534792  0.0540876  -0.989 0.322785    
`Education^5`              -0.0164560  0.0305847  -0.538 0.590545    
Income.L                   -0.3919325  0.0289449 -13.541  &lt; 2e-16 ***
Income.Q                   -0.0754943  0.0248551  -3.037 0.002386 ** 
Income.C                   -0.0036273  0.0237681  -0.153 0.878705    
`Income^4`                 -0.0240004  0.0237376  -1.011 0.311982    
`Income^5`                 -0.0097538  0.0233498  -0.418 0.676148    
`Income^6`                 -0.0108508  0.0228148  -0.476 0.634357    
`Income^7`                  0.0131927  0.0225212   0.586 0.558017    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 143396  on 177576  degrees of freedom
Residual deviance: 112441  on 177531  degrees of freedom
AIC: 112533

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
<p>Model 2 is fit the same way. Even though variables were selected using EDA, the log loss is slightly higher than that for model 1, with a value of 0.319.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run logistic regression on Model 2</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>logRegFit_M2 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain2,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"glm"</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss))</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>logRegFit_M2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized Linear Model 

177577 samples
    13 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss  
  0.3186222</code></pre>
</div>
</div>
<p>The summary of model 2 is below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logRegFit_M2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
NULL

Coefficients:
                          Estimate Std. Error  z value Pr(&gt;|z|)    
(Intercept)             -4.5391110  0.0423776 -107.111  &lt; 2e-16 ***
HighBPYes                0.7533312  0.0176006   42.801  &lt; 2e-16 ***
HighCholYes              0.5384371  0.0162638   33.106  &lt; 2e-16 ***
BMI                      0.0577817  0.0010819   53.410  &lt; 2e-16 ***
StrokeYes                0.1479984  0.0297927    4.968 6.78e-07 ***
HeartDiseaseorAttackYes  0.2973285  0.0210240   14.142  &lt; 2e-16 ***
PhysActivityYes         -0.0544293  0.0169485   -3.211 0.001321 ** 
HvyAlcoholConsumpYes    -0.7870973  0.0462350  -17.024  &lt; 2e-16 ***
GenHlth.L                1.6873671  0.0347504   48.557  &lt; 2e-16 ***
GenHlth.Q               -0.3614216  0.0263392  -13.722  &lt; 2e-16 ***
GenHlth.C               -0.0650016  0.0199257   -3.262 0.001106 ** 
`GenHlth^4`              0.0146550  0.0147723    0.992 0.321168    
MentHlth                -0.0039172  0.0010056   -3.895 9.81e-05 ***
PhysHlth                -0.0036978  0.0009611   -3.847 0.000119 ***
DiffWalkYes              0.1143075  0.0201263    5.680 1.35e-08 ***
Age.L                    2.2848968  0.0803946   28.421  &lt; 2e-16 ***
Age.Q                   -0.7524727  0.0760543   -9.894  &lt; 2e-16 ***
Age.C                   -0.2595695  0.0706335   -3.675 0.000238 ***
`Age^4`                 -0.0329026  0.0673990   -0.488 0.625425    
`Age^5`                 -0.1720643  0.0648336   -2.654 0.007956 ** 
`Age^6`                  0.0837446  0.0607780    1.378 0.168241    
`Age^7`                  0.0088728  0.0556861    0.159 0.873405    
`Age^8`                  0.0157097  0.0497889    0.316 0.752363    
`Age^9`                 -0.0111388  0.0435379   -0.256 0.798073    
`Age^10`                -0.0903360  0.0378650   -2.386 0.017045 *  
`Age^11`                 0.0612326  0.0333078    1.838 0.066006 .  
`Age^12`                 0.0262475  0.0283345    0.926 0.354266    
Income.L                -0.3502377  0.0264531  -13.240  &lt; 2e-16 ***
Income.Q                -0.0569607  0.0243932   -2.335 0.019538 *  
Income.C                -0.0041762  0.0236997   -0.176 0.860127    
`Income^4`              -0.0237810  0.0236771   -1.004 0.315192    
`Income^5`              -0.0074909  0.0232958   -0.322 0.747790    
`Income^6`              -0.0109228  0.0227628   -0.480 0.631334    
`Income^7`               0.0103935  0.0224654    0.463 0.643621    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 143396  on 177576  degrees of freedom
Residual deviance: 113093  on 177543  degrees of freedom
AIC: 113161

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
<p>Model 3 includes the fewest variables and has the highest log loss, although it isn’t that different at 0.320. More important than log loss on the trained model is how the model generalizes to new data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run logistic regression on Model 3</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>logRegFit_M3 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain3,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"glm"</span>,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss))</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>logRegFit_M3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized Linear Model 

177577 samples
     8 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss  
  0.3198399</code></pre>
</div>
</div>
<p>The summary of model 3 is below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logRegFit_M3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
NULL

Coefficients:
                          Estimate Std. Error  z value Pr(&gt;|z|)    
(Intercept)             -4.6571280  0.0392275 -118.721  &lt; 2e-16 ***
HighBPYes                0.7495382  0.0175460   42.719  &lt; 2e-16 ***
HighCholYes              0.5366971  0.0162155   33.098  &lt; 2e-16 ***
BMI                      0.0598307  0.0010639   56.235  &lt; 2e-16 ***
HeartDiseaseorAttackYes  0.3232129  0.0207417   15.583  &lt; 2e-16 ***
GenHlth.L                1.7266609  0.0339903   50.799  &lt; 2e-16 ***
GenHlth.Q               -0.3559608  0.0262311  -13.570  &lt; 2e-16 ***
GenHlth.C               -0.0702951  0.0198837   -3.535 0.000407 ***
`GenHlth^4`              0.0125401  0.0147408    0.851 0.394931    
PhysHlth                -0.0026339  0.0009074   -2.903 0.003701 ** 
Age.L                    2.3956775  0.0799208   29.976  &lt; 2e-16 ***
Age.Q                   -0.7436426  0.0761212   -9.769  &lt; 2e-16 ***
Age.C                   -0.2502661  0.0707240   -3.539 0.000402 ***
`Age^4`                 -0.0290299  0.0674754   -0.430 0.667029    
`Age^5`                 -0.1686328  0.0648921   -2.599 0.009359 ** 
`Age^6`                  0.0851086  0.0608178    1.399 0.161692    
`Age^7`                  0.0142138  0.0557264    0.255 0.798674    
`Age^8`                  0.0114648  0.0498344    0.230 0.818047    
`Age^9`                 -0.0044975  0.0435713   -0.103 0.917786    
`Age^10`                -0.0899010  0.0378837   -2.373 0.017640 *  
`Age^11`                 0.0610976  0.0333149    1.834 0.066663 .  
`Age^12`                 0.0275538  0.0283247    0.973 0.330662    
Income.L                -0.3889062  0.0258814  -15.026  &lt; 2e-16 ***
Income.Q                -0.0646285  0.0243153   -2.658 0.007862 ** 
Income.C                -0.0022834  0.0236391   -0.097 0.923048    
`Income^4`              -0.0247702  0.0236208   -1.049 0.294336    
`Income^5`              -0.0062340  0.0232401   -0.268 0.788512    
`Income^6`              -0.0123309  0.0227036   -0.543 0.587044    
`Income^7`               0.0086819  0.0224067    0.387 0.698408    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 143396  on 177576  degrees of freedom
Residual deviance: 113531  on 177548  degrees of freedom
AIC: 113589

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
<p>Overall, model 1 with 21 variables is the best model based on the log loss.</p>
</section>
<section id="classification-tree" class="level2">
<h2 class="anchored" data-anchor-id="classification-tree">Classification Tree</h2>
<p>Classification trees, also referred to as decision trees, are another way to predict class membership. The predictor space is split into regions in using the Gini Index or Entropy. The Gini Index measures impurity of a node, which is an indication of how well a node separates the classes. After the tree is grown it is pruned back by removing nodes that do not provide much predictive improvement. For purposes of identifying class membership, classification trees assign membership based on the most prevalent class in the region. Because the diabetes data set has a categorical response variable, the classification tree is appropriate to use for prediction of the two classes.</p>
<p>Fitting a classification tree using caret is similar to logistic regression except the method is “rpart” and we can add a tuning parameter. The tuning parameter is called the complexity parameter (cp) and this parameter helps control the size of the tree. The parameter is used for the pruning process and the model evaluated for each cp using log loss. A lower cp means less pruning.</p>
<p>The tree fit for Model 1 is shown before. The algorithm determined that a complexity parameter of 0.002 produced the optimal model with a log loss of 0.356.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run tree fitting on Model 1</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>treeFit_M1 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain1,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"rpart"</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.001</span>)))</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>treeFit_M1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CART 

177577 samples
    21 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results across tuning parameters:

  cp     logLoss  
  0.000  0.4405007
  0.001  0.3559044
  0.002  0.3558902
  0.003  0.3559745
  0.004  0.3559933
  0.005  0.3656972
  0.006  0.3748596
  0.007  0.4037576
  0.008  0.4037576
  0.009  0.4037576
  0.010  0.4037576
  0.011  0.4037576
  0.012  0.4037576
  0.013  0.4037576
  0.014  0.4037576
  0.015  0.4037576
  0.016  0.4037576
  0.017  0.4037576
  0.018  0.4037576
  0.019  0.4037576
  0.020  0.4037576
  0.021  0.4037576
  0.022  0.4037576
  0.023  0.4037576
  0.024  0.4037576
  0.025  0.4037576
  0.026  0.4037576
  0.027  0.4037576
  0.028  0.4037576
  0.029  0.4037576
  0.030  0.4037576
  0.031  0.4037576
  0.032  0.4037576
  0.033  0.4037576
  0.034  0.4037576
  0.035  0.4037576
  0.036  0.4037576
  0.037  0.4037576
  0.038  0.4037576
  0.039  0.4037576
  0.040  0.4037576
  0.041  0.4037576
  0.042  0.4037576
  0.043  0.4037576
  0.044  0.4037576
  0.045  0.4037576
  0.046  0.4037576
  0.047  0.4037576
  0.048  0.4037576
  0.049  0.4037576
  0.050  0.4037576
  0.051  0.4037576
  0.052  0.4037576
  0.053  0.4037576
  0.054  0.4037576
  0.055  0.4037576
  0.056  0.4037576
  0.057  0.4037576
  0.058  0.4037576
  0.059  0.4037576
  0.060  0.4037576
  0.061  0.4037576
  0.062  0.4037576
  0.063  0.4037576
  0.064  0.4037576
  0.065  0.4037576
  0.066  0.4037576
  0.067  0.4037576
  0.068  0.4037576
  0.069  0.4037576
  0.070  0.4037576
  0.071  0.4037576
  0.072  0.4037576
  0.073  0.4037576
  0.074  0.4037576
  0.075  0.4037576
  0.076  0.4037576
  0.077  0.4037576
  0.078  0.4037576
  0.079  0.4037576
  0.080  0.4037576
  0.081  0.4037576
  0.082  0.4037576
  0.083  0.4037576
  0.084  0.4037576
  0.085  0.4037576
  0.086  0.4037576
  0.087  0.4037576
  0.088  0.4037576
  0.089  0.4037576
  0.090  0.4037576
  0.091  0.4037576
  0.092  0.4037576
  0.093  0.4037576
  0.094  0.4037576
  0.095  0.4037576
  0.096  0.4037576
  0.097  0.4037576
  0.098  0.4037576
  0.099  0.4037576
  0.100  0.4037576

logLoss was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.002.</code></pre>
</div>
</div>
<p>The tree fit for Model 2 is shown below. The optimal model also had a log loss of 0.356 and used a complexity parameter of 0.002.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run tree fitting on Model 2</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>treeFit_M2 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain2,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"rpart"</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.001</span>)))</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>treeFit_M2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CART 

177577 samples
    13 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results across tuning parameters:

  cp     logLoss  
  0.000  0.4058828
  0.001  0.3559044
  0.002  0.3558902
  0.003  0.3559745
  0.004  0.3559933
  0.005  0.3656972
  0.006  0.3748596
  0.007  0.4037576
  0.008  0.4037576
  0.009  0.4037576
  0.010  0.4037576
  0.011  0.4037576
  0.012  0.4037576
  0.013  0.4037576
  0.014  0.4037576
  0.015  0.4037576
  0.016  0.4037576
  0.017  0.4037576
  0.018  0.4037576
  0.019  0.4037576
  0.020  0.4037576
  0.021  0.4037576
  0.022  0.4037576
  0.023  0.4037576
  0.024  0.4037576
  0.025  0.4037576
  0.026  0.4037576
  0.027  0.4037576
  0.028  0.4037576
  0.029  0.4037576
  0.030  0.4037576
  0.031  0.4037576
  0.032  0.4037576
  0.033  0.4037576
  0.034  0.4037576
  0.035  0.4037576
  0.036  0.4037576
  0.037  0.4037576
  0.038  0.4037576
  0.039  0.4037576
  0.040  0.4037576
  0.041  0.4037576
  0.042  0.4037576
  0.043  0.4037576
  0.044  0.4037576
  0.045  0.4037576
  0.046  0.4037576
  0.047  0.4037576
  0.048  0.4037576
  0.049  0.4037576
  0.050  0.4037576
  0.051  0.4037576
  0.052  0.4037576
  0.053  0.4037576
  0.054  0.4037576
  0.055  0.4037576
  0.056  0.4037576
  0.057  0.4037576
  0.058  0.4037576
  0.059  0.4037576
  0.060  0.4037576
  0.061  0.4037576
  0.062  0.4037576
  0.063  0.4037576
  0.064  0.4037576
  0.065  0.4037576
  0.066  0.4037576
  0.067  0.4037576
  0.068  0.4037576
  0.069  0.4037576
  0.070  0.4037576
  0.071  0.4037576
  0.072  0.4037576
  0.073  0.4037576
  0.074  0.4037576
  0.075  0.4037576
  0.076  0.4037576
  0.077  0.4037576
  0.078  0.4037576
  0.079  0.4037576
  0.080  0.4037576
  0.081  0.4037576
  0.082  0.4037576
  0.083  0.4037576
  0.084  0.4037576
  0.085  0.4037576
  0.086  0.4037576
  0.087  0.4037576
  0.088  0.4037576
  0.089  0.4037576
  0.090  0.4037576
  0.091  0.4037576
  0.092  0.4037576
  0.093  0.4037576
  0.094  0.4037576
  0.095  0.4037576
  0.096  0.4037576
  0.097  0.4037576
  0.098  0.4037576
  0.099  0.4037576
  0.100  0.4037576

logLoss was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.002.</code></pre>
</div>
</div>
<p>The tree fit for Model 3 is shown below. As with the previous two models, the algorithm selected a cp of 0.002, corresponding to a log loss of 0.356.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run tree fitting on Model 3</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>treeFit_M3 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain3,</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"rpart"</span>,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>                   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.001</span>)))</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>treeFit_M3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CART 

177577 samples
     8 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results across tuning parameters:

  cp     logLoss  
  0.000  0.3684045
  0.001  0.3559044
  0.002  0.3558902
  0.003  0.3559745
  0.004  0.3559933
  0.005  0.3656972
  0.006  0.3748596
  0.007  0.4037576
  0.008  0.4037576
  0.009  0.4037576
  0.010  0.4037576
  0.011  0.4037576
  0.012  0.4037576
  0.013  0.4037576
  0.014  0.4037576
  0.015  0.4037576
  0.016  0.4037576
  0.017  0.4037576
  0.018  0.4037576
  0.019  0.4037576
  0.020  0.4037576
  0.021  0.4037576
  0.022  0.4037576
  0.023  0.4037576
  0.024  0.4037576
  0.025  0.4037576
  0.026  0.4037576
  0.027  0.4037576
  0.028  0.4037576
  0.029  0.4037576
  0.030  0.4037576
  0.031  0.4037576
  0.032  0.4037576
  0.033  0.4037576
  0.034  0.4037576
  0.035  0.4037576
  0.036  0.4037576
  0.037  0.4037576
  0.038  0.4037576
  0.039  0.4037576
  0.040  0.4037576
  0.041  0.4037576
  0.042  0.4037576
  0.043  0.4037576
  0.044  0.4037576
  0.045  0.4037576
  0.046  0.4037576
  0.047  0.4037576
  0.048  0.4037576
  0.049  0.4037576
  0.050  0.4037576
  0.051  0.4037576
  0.052  0.4037576
  0.053  0.4037576
  0.054  0.4037576
  0.055  0.4037576
  0.056  0.4037576
  0.057  0.4037576
  0.058  0.4037576
  0.059  0.4037576
  0.060  0.4037576
  0.061  0.4037576
  0.062  0.4037576
  0.063  0.4037576
  0.064  0.4037576
  0.065  0.4037576
  0.066  0.4037576
  0.067  0.4037576
  0.068  0.4037576
  0.069  0.4037576
  0.070  0.4037576
  0.071  0.4037576
  0.072  0.4037576
  0.073  0.4037576
  0.074  0.4037576
  0.075  0.4037576
  0.076  0.4037576
  0.077  0.4037576
  0.078  0.4037576
  0.079  0.4037576
  0.080  0.4037576
  0.081  0.4037576
  0.082  0.4037576
  0.083  0.4037576
  0.084  0.4037576
  0.085  0.4037576
  0.086  0.4037576
  0.087  0.4037576
  0.088  0.4037576
  0.089  0.4037576
  0.090  0.4037576
  0.091  0.4037576
  0.092  0.4037576
  0.093  0.4037576
  0.094  0.4037576
  0.095  0.4037576
  0.096  0.4037576
  0.097  0.4037576
  0.098  0.4037576
  0.099  0.4037576
  0.100  0.4037576

logLoss was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.002.</code></pre>
</div>
</div>
<p>All 3 models for classification tree fitting had the same log loss so all three will be used in the model comparisons to identify the best model overall.</p>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<p>Random forest is an ensemble learning method. Ensemble methods produce many trees and average across these trees to determine prediction, often resulting in better predictions. Random forests are similar to bagging, but instead of using all predictors, uses fewer, randomly selected predictors. This random selection of features occurs at each split. This helps reduce correlation and variance when there are particularly strong predictors present in the data. The process for random forests involves creating bootstrap samples to fit on which allows the creation of multiple trees to be averaged across. To create bootstrap samples, the data is treated as a population and resampled with replacement. The random forest method is applied to each of these samples, each time creating a tree. The algorithm for determining splits is the same as classification trees, which involves minimizing the Gini Index. The randomization of variables and use of bootstrap samples prevents the need for pruning for ensemble methods such as random forests. Although the word “average” has been used here, for classification this means using majority vote to determine group membership. Using random forest is of interest for the models proposed here because it allows assignment of observations to the two classes, Non_Diabetic or Prediabetic_Diabetic, but is often more advantageous than classification trees because it produces many trees and usually results in better predictions.</p>
<p>Random Forest fitting in the caret package uses “rf” for the method. Settings for trainControl are the same as before. Random forests have one available tuning parameter, mtry. The mtry tuning parameter refers to the number of randomly selected predictors to use. You can also specify the number of trees for the model to average, which also corresponds to the number of bootstrap samples. This parameter is ntree and the default in caret is 500 trees. A rule of thumb for mtry for classification trees is the square root of the number of parameters.</p>
<p>Model 1 has 21 parameters so the mtry could be set to 5. The mtry can be set to a higher number, but can significantly increase computation time. Due to computational issues and poorer log loss compared to the previous models, ntree was set to 50 and mtry 1:21 to identify the best mtry for the model. The best mtry for ntree 50 was 16, with a log loss of 0.518. The model was run again with ntree 100 and mtry 13:16. In this case, mtry 15 was slightly better than mtry 16, with a log loss of 0.455 compared to 0.460.</p>
<p>The final fitting of Model 1 to a random forest is presented below, using ntree 200 and mtry 15. The log loss at this ntree is 0.421.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run random forest fitting on Model 1</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>rfFit_M1 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain1,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"rf"</span>,</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ntree =</span> <span class="dv">200</span>,</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="dv">15</span>))</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>rfFit_M1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

177577 samples
    21 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss  
  0.4211159

Tuning parameter 'mtry' was held constant at a value of 15</code></pre>
</div>
</div>
<p>For Model 2, at ntree 50, log loss decreased as mtry increased, with a log loss of 2.77 at mtry 1 and a log loss of 0.811 at mtry 13. The model was run again using ntree 200 and mtry 13, resulting in a log loss of 0.65. Increasing ntree to 400 improved the log loss (0.599) but took too much time computationally. Since the mtry of 13 is the total number of predictors in this model, this random forest is actually equivalent to bagging.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run random forest fitting on Model 2</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>rfFit_M2 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain2,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"rf"</span>,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ntree =</span> <span class="dv">200</span>,</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="dv">13</span>))</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>rfFit_M2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

177577 samples
    13 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss  
  0.6495957

Tuning parameter 'mtry' was held constant at a value of 13</code></pre>
</div>
</div>
<p>Model 3 was fit similarly to the other random forest models. A ntree of 50 was used to identify the best mtry and then that mtry was used with a ntree of 200. For this model, at ntree 50, the log loss decreased as mtry increased, with a mtry of 1 giving a log loss of 3.08 and mtry 8 giving a log loss of 1.22. The data was fit again at ntree 100 using mtry 7:8 and again mtry 8 gave the best log loss at 1.07. The data was then fit using ntree 200 and mtry 8, which is presented below. The log loss is 0.956. Since the optimal mtry is 8, the number of predictors in Model 3, this random forest is equivalent to bagging.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run random forest fitting on Model 3</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>rfFit_M3 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> ., </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> diabetesTrain3,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">"rf"</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>                                           <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ntree =</span> <span class="dv">200</span>,</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>                  <span class="at">tuneGrid =</span> <span class="fu">data.frame</span>(<span class="at">mtry =</span> <span class="dv">8</span>))</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>rfFit_M3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

177577 samples
     8 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss 
  0.955829

Tuning parameter 'mtry' was held constant at a value of 8</code></pre>
</div>
</div>
<p>It is apparent and makes sense that log loss decreases as ntree increases and it would perhaps drop even more if higher ntree were used, but there is a point of diminishing returns and overall the random forest models do not appear to be as good as the logistic regression and classification tree models based off the log loss results.</p>
<p>Another option is to use the “ranger” method. It has additional tuning parameters and often computes faster than “rf”. Ranger can accept 3 tuning parameters, mtry, splitrule and min.node.size. The splitrule parameter is gini by default. Another option is extratrees, which introduces additional randomness and can be better for data that isn’t balanced. The min.node.size parameter refers to the minimum number of observations in terminal nodes. Higher node size makes the model simpler by requiring more observations to make a split.</p>
<p>The “ranger” method was only used on model 1 due to extensive computation times (hours) for optimizing tuning parameters. It was initially run with num.trees 50, mtry 1:21, splitrule extratrees and min.node.size of c(5, 10, 20, 30, 40, 50). The optimal model had an mtry of 5 and a min.node.size of 50. The log loss with these parameters and num.trees 200 is 0.321.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set seed for reproducibility</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Run random forest on model 1</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>rfFit_ranger_M1 <span class="ot">&lt;-</span> <span class="fu">train</span>(Diabetes_binary <span class="sc">~</span> .,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> diabetesTrain1,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">method =</span> <span class="st">"ranger"</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>                         <span class="at">metric =</span> <span class="st">"logLoss"</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, </span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">summaryFunction =</span> mnLogLoss),</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>                         <span class="at">num.trees =</span> <span class="dv">200</span>,</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>                         <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="dv">5</span>, </span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">splitrule =</span> <span class="st">"extratrees"</span>,</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">min.node.size =</span> <span class="dv">50</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Growing trees.. Progress: 95%. Estimated remaining time: 1 seconds.
Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.
Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.
Growing trees.. Progress: 95%. Estimated remaining time: 1 seconds.
Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.
Growing trees.. Progress: 68%. Estimated remaining time: 14 seconds.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>rfFit_ranger_M1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

177577 samples
    21 predictor
     2 classes: 'Non_Diabetic', 'Prediabetic_Diabetic' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 142061, 142063, 142061, 142061, 142062 
Resampling results:

  logLoss  
  0.3213257

Tuning parameter 'mtry' was held constant at a value of 5
Tuning
 parameter 'splitrule' was held constant at a value of extratrees

Tuning parameter 'min.node.size' was held constant at a value of 50</code></pre>
</div>
</div>
<p>Overall, the best fit was model 1 using “ranger”, giving a log loss of 0.322.</p>
</section>
<section id="final-model-selection" class="level2">
<h2 class="anchored" data-anchor-id="final-model-selection">Final Model Selection</h2>
<p>Now that the model training is complete, the best models for each type of classification can be compared. The models to be compared are Model 1 logistic regression, Model 1 random forest and all 3 classification tree models since they all had the same log loss. The first step is to calculate predictions based on the model fit using the test data. This is done using predict(), where the fit is indicated along with newdata as the relevant test set. The type needs to be set to “prob” for probability since log loss was used in the model fitting. The predicted probabilities can be combined with the true class labels from the data (Diabetes_binary) to get an easy comparison of what the predicted class is compared to the true class.</p>
<p>Once the predicted probabilities are obtained, they can be used to calculate log loss for each model. This metric can be used to determine which model is the best at predicting. The probabilities can also be converted to class labels to produce a confusion matrix, which gives accuracy, but one must remember that if the model is poor at predicting the minority class and good at predicting the majority class, the accuracy can be misleading. In such cases, other metrics in the confusion matrix need to be considered to accurately access how the model performs.</p>
<section id="logistic-regression-model-1" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-model-1">Logistic Regression Model 1</h3>
<p>A table of predicted values for the best logistic regression model is below. The actual classes from the test data were added using bind_cols() for purposes of comparison.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions using test data</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>pred_logReg <span class="ot">&lt;-</span> <span class="fu">predict</span>(logRegFit_M1, <span class="at">newdata =</span> diabetesTest1, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">#extract response column Diabetes_binary from test data</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>Actual <span class="ot">&lt;-</span> diabetesTest1<span class="sc">$</span>Diabetes_binary</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co">#combine predicted probabilities with actual class labels</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>pred_logReg_actual_table <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pred_logReg, <span class="at">Actual =</span> Actual)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>pred_logReg_actual_table <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(pred_logReg_actual_table)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>pred_logReg_actual_table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 3
   Non_Diabetic Prediabetic_Diabetic Actual              
          &lt;dbl&gt;                &lt;dbl&gt; &lt;fct&gt;               
 1        0.658              0.342   Non_Diabetic        
 2        0.952              0.0482  Non_Diabetic        
 3        0.944              0.0562  Non_Diabetic        
 4        0.870              0.130   Non_Diabetic        
 5        0.939              0.0613  Non_Diabetic        
 6        0.998              0.00177 Non_Diabetic        
 7        0.729              0.271   Non_Diabetic        
 8        0.260              0.740   Prediabetic_Diabetic
 9        0.418              0.582   Prediabetic_Diabetic
10        0.910              0.0898  Non_Diabetic        
# ℹ 76,093 more rows</code></pre>
</div>
</div>
<p>The log Loss for this model on the test data can be obtained using logLoss() from the Metrics package. This function takes 2 arguments, both vectors, with one being the actual response values for Diabetes_binary in the test data, and the other the predictions, which are the probabilities for the positive class. To perform this calculation, though, the Diabetes_binary levels need to be numeric. After converting the Diabetes_binary column to numbers, log loss can be computed with vector arguments being Diabetes_binary from the test set and the positive class, Prediabetic_Diabetic, from the test set predictions. The log loss for this model is 0.318.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#covert Diabetes_binary to numbers</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>numeric_diabetes1 <span class="ot">&lt;-</span> diabetesTest1 <span class="sc">|&gt;</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Diabetes_binary =</span> </span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>           <span class="fu">ifelse</span>(Diabetes_binary <span class="sc">==</span> <span class="st">"Prediabetic_Diabetic"</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate log loss for best logistic regression model</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>logReg_log_loss <span class="ot">&lt;-</span> <span class="fu">logLoss</span>(numeric_diabetes1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>                           pred_logReg<span class="sc">$</span>Prediabetic_Diabetic)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>logReg_log_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3179013</code></pre>
</div>
</div>
<p>To obtain a confusion matrix, the probabilities need to be converted to class labels. This is done using predict() but specifying “raw” as the type instead of “prob”. The confusion matrix can be obtained using confusionMatrix(), which accepts the arguments of the predictions and the actual values from the Diabetes_binary column of the test set. The option for positive was specified to ensure the positive class was correctly assigned. In looking at the output, while the accuracy is 86.5%, it can be seen from the matrix that prediabetic/diabetics have close to the same number of false positives as true positives. This is reflected in the Positive Predictive Value metric, which indicates that when the model predicts prediabetics/diabetics, it is correct 55.1% of the time. This is in contrast to the non-diabetic class, which is predicted correctly 87.7% of the time. The relatively poor identification of the Prediabetic_Diabetic class is also reflected in the low sensitivity of 15.2%, which means that the model correctly identifies 15.2% of all actual prediabetic/diabetic cases.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions based on class</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>pred_logReg_class <span class="ot">&lt;-</span> <span class="fu">predict</span>(logRegFit_M1, <span class="at">newdata =</span> diabetesTest1, </span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">type =</span> <span class="st">"raw"</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate confusion matrix</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>logReg_confusion <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_logReg_class, </span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>                                    diabetesTest1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">positive =</span> <span class="st">"Prediabetic_Diabetic"</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>logReg_confusion</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                      Reference
Prediction             Non_Diabetic Prediabetic_Diabetic
  Non_Diabetic                64182                 8988
  Prediabetic_Diabetic         1318                 1615
                                              
               Accuracy : 0.8646              
                 95% CI : (0.8621, 0.867)     
    No Information Rate : 0.8607              
    P-Value [Acc &gt; NIR] : 0.0009204           
                                              
                  Kappa : 0.1897              
                                              
 Mcnemar's Test P-Value : &lt; 2.2e-16           
                                              
            Sensitivity : 0.15232             
            Specificity : 0.97988             
         Pos Pred Value : 0.55063             
         Neg Pred Value : 0.87716             
             Prevalence : 0.13932             
         Detection Rate : 0.02122             
   Detection Prevalence : 0.03854             
      Balanced Accuracy : 0.56610             
                                              
       'Positive' Class : Prediabetic_Diabetic
                                              </code></pre>
</div>
</div>
</section>
<section id="classification-tree-model-1" class="level3">
<h3 class="anchored" data-anchor-id="classification-tree-model-1">Classification Tree Model 1</h3>
<p>A table of predicted values for classification tree Model is below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>pred_tree1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(treeFit_M1, <span class="at">newdata =</span> diabetesTest1, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co">#combine predicted probabilitie with actual class labels</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table1 <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pred_tree1, <span class="at">Actual =</span> Actual)</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table1 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(pred_tree_actual_table1)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 3
   Non_Diabetic Prediabetic_Diabetic Actual              
          &lt;dbl&gt;                &lt;dbl&gt; &lt;fct&gt;               
 1        0.681               0.319  Non_Diabetic        
 2        0.940               0.0602 Non_Diabetic        
 3        0.940               0.0602 Non_Diabetic        
 4        0.940               0.0602 Non_Diabetic        
 5        0.813               0.187  Non_Diabetic        
 6        0.940               0.0602 Non_Diabetic        
 7        0.813               0.187  Non_Diabetic        
 8        0.396               0.604  Prediabetic_Diabetic
 9        0.681               0.319  Prediabetic_Diabetic
10        0.813               0.187  Non_Diabetic        
# ℹ 76,093 more rows</code></pre>
</div>
</div>
<p>The log loss for Model 1 on the test data is below. The log loss for this model on the test set is 0.357.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate log loss for best random forest model</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co">#use numeric_diabetes1 from logistic regression since it is the same test set</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>tree_log_loss1 <span class="ot">&lt;-</span> <span class="fu">logLoss</span>(numeric_diabetes1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>                           pred_tree1<span class="sc">$</span>Prediabetic_Diabetic)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>tree_log_loss1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3569434</code></pre>
</div>
</div>
<p>The confusion matrix was computed as with the logistic regression model. Accuracy is 86.5%, but is biased because it is better at predicting the Non_Diabetic class. For the Prediabetic_Diabetic class, of all positive predictions, the model classifies correctly 57.1% of the time. In comparison, the Non_Diabetic class is accurately assigned 87.3% of the time. The sensitivity is also low, indicating that the model correctly identifies 11.6% of all actual prediabetic/diabetic cases. The accuracy is higher than the no information rate, but the small difference between the two also suggests that the model is not effectively distinguishing between the classes given the imbalance in the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions based on class</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>pred_tree_class1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(treeFit_M1, <span class="at">newdata =</span> diabetesTest1, </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">type =</span> <span class="st">"raw"</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate confusion matrix</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>tree_confusion1 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_tree_class1, </span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>                                    diabetesTest1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">positive =</span> <span class="st">"Prediabetic_Diabetic"</span>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>tree_confusion1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                      Reference
Prediction             Non_Diabetic Prediabetic_Diabetic
  Non_Diabetic                64575                 9374
  Prediabetic_Diabetic          925                 1229
                                              
               Accuracy : 0.8647              
                 95% CI : (0.8622, 0.8671)    
    No Information Rate : 0.8607              
    P-Value [Acc &gt; NIR] : 0.0007147           
                                              
                  Kappa : 0.1528              
                                              
 Mcnemar's Test P-Value : &lt; 2.2e-16           
                                              
            Sensitivity : 0.11591             
            Specificity : 0.98588             
         Pos Pred Value : 0.57057             
         Neg Pred Value : 0.87324             
             Prevalence : 0.13932             
         Detection Rate : 0.01615             
   Detection Prevalence : 0.02830             
      Balanced Accuracy : 0.55089             
                                              
       'Positive' Class : Prediabetic_Diabetic
                                              </code></pre>
</div>
</div>
</section>
<section id="classification-tree-model-2" class="level3">
<h3 class="anchored" data-anchor-id="classification-tree-model-2">Classification Tree Model 2</h3>
<p>Now we can examine Model 2 for the classification tree. The table of predictions is presented below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions using test data</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>pred_tree2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(treeFit_M2, <span class="at">newdata =</span> diabetesTest2, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co">#combine predicted probabilitie with actual class labels</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table2 <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pred_tree2, <span class="at">Actual =</span> Actual)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table2 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(pred_tree_actual_table2)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 3
   Non_Diabetic Prediabetic_Diabetic Actual              
          &lt;dbl&gt;                &lt;dbl&gt; &lt;fct&gt;               
 1        0.681               0.319  Non_Diabetic        
 2        0.940               0.0602 Non_Diabetic        
 3        0.940               0.0602 Non_Diabetic        
 4        0.940               0.0602 Non_Diabetic        
 5        0.813               0.187  Non_Diabetic        
 6        0.940               0.0602 Non_Diabetic        
 7        0.813               0.187  Non_Diabetic        
 8        0.396               0.604  Prediabetic_Diabetic
 9        0.681               0.319  Prediabetic_Diabetic
10        0.813               0.187  Non_Diabetic        
# ℹ 76,093 more rows</code></pre>
</div>
</div>
<p>The log loss for this model on the test data is below. The log loss is the same as that for Model 1 with 21 variables, 0.357.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co">#covert Diabetes_binary to numbers</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>numeric_diabetes2 <span class="ot">&lt;-</span> diabetesTest2 <span class="sc">|&gt;</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Diabetes_binary =</span> </span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>           <span class="fu">ifelse</span>(Diabetes_binary <span class="sc">==</span> <span class="st">"Prediabetic_Diabetic"</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate log loss for best classification tree model</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>tree_log_loss2 <span class="ot">&lt;-</span> <span class="fu">logLoss</span>(numeric_diabetes2<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>                           pred_tree2<span class="sc">$</span>Prediabetic_Diabetic)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>tree_log_loss2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3569434</code></pre>
</div>
</div>
<p>The confusion matrix output is below. The results appear to be identical to the output for Model 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions based on class</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>pred_tree_class2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(treeFit_M2, <span class="at">newdata =</span> diabetesTest2, </span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">type =</span> <span class="st">"raw"</span>)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate confusion matrix</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>tree_confusion2 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_tree_class2, </span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>                                    diabetesTest2<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">positive =</span> <span class="st">"Prediabetic_Diabetic"</span>)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>tree_confusion2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                      Reference
Prediction             Non_Diabetic Prediabetic_Diabetic
  Non_Diabetic                64575                 9374
  Prediabetic_Diabetic          925                 1229
                                              
               Accuracy : 0.8647              
                 95% CI : (0.8622, 0.8671)    
    No Information Rate : 0.8607              
    P-Value [Acc &gt; NIR] : 0.0007147           
                                              
                  Kappa : 0.1528              
                                              
 Mcnemar's Test P-Value : &lt; 2.2e-16           
                                              
            Sensitivity : 0.11591             
            Specificity : 0.98588             
         Pos Pred Value : 0.57057             
         Neg Pred Value : 0.87324             
             Prevalence : 0.13932             
         Detection Rate : 0.01615             
   Detection Prevalence : 0.02830             
      Balanced Accuracy : 0.55089             
                                              
       'Positive' Class : Prediabetic_Diabetic
                                              </code></pre>
</div>
</div>
</section>
<section id="classification-tree-model-3" class="level3">
<h3 class="anchored" data-anchor-id="classification-tree-model-3">Classification Tree Model 3</h3>
<p>A table of predicted values for classification tree Model 3 is below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions using test data</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>pred_tree3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(treeFit_M3, <span class="at">newdata =</span> diabetesTest3, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co">#combine predicted probabilities with actual class labels</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table3 <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pred_tree3, <span class="at">Actual =</span> Actual)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table3 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(pred_tree_actual_table3)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>pred_tree_actual_table3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 3
   Non_Diabetic Prediabetic_Diabetic Actual              
          &lt;dbl&gt;                &lt;dbl&gt; &lt;fct&gt;               
 1        0.681               0.319  Non_Diabetic        
 2        0.940               0.0602 Non_Diabetic        
 3        0.940               0.0602 Non_Diabetic        
 4        0.940               0.0602 Non_Diabetic        
 5        0.813               0.187  Non_Diabetic        
 6        0.940               0.0602 Non_Diabetic        
 7        0.813               0.187  Non_Diabetic        
 8        0.396               0.604  Prediabetic_Diabetic
 9        0.681               0.319  Prediabetic_Diabetic
10        0.813               0.187  Non_Diabetic        
# ℹ 76,093 more rows</code></pre>
</div>
</div>
<p>The log loss output for this model on the test data is below. The log loss for this model is 0.357, the same as that for models 1 and 2.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co">#covert Diabetes_binary to numbers</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>numeric_diabetes3 <span class="ot">&lt;-</span> diabetesTest3 <span class="sc">|&gt;</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Diabetes_binary =</span> </span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>           <span class="fu">ifelse</span>(Diabetes_binary <span class="sc">==</span> <span class="st">"Prediabetic_Diabetic"</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate log loss for best classification tree model</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>tree_log_loss3 <span class="ot">&lt;-</span> <span class="fu">logLoss</span>(numeric_diabetes3<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>                          pred_tree3<span class="sc">$</span>Prediabetic_Diabetic)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>tree_log_loss3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3569434</code></pre>
</div>
</div>
<p>The confusion matrix for classification tree Model 3 is presented below. The output results are the same as those for models 1 and 2.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions based on class</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>pred_tree_class3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(treeFit_M3, <span class="at">newdata =</span> diabetesTest3, </span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">type =</span> <span class="st">"raw"</span>)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate confusion matrix</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>tree_confusion3 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_tree_class3, </span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>                                   diabetesTest3<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">positive =</span> <span class="st">"Prediabetic_Diabetic"</span>)</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>tree_confusion3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                      Reference
Prediction             Non_Diabetic Prediabetic_Diabetic
  Non_Diabetic                64575                 9374
  Prediabetic_Diabetic          925                 1229
                                              
               Accuracy : 0.8647              
                 95% CI : (0.8622, 0.8671)    
    No Information Rate : 0.8607              
    P-Value [Acc &gt; NIR] : 0.0007147           
                                              
                  Kappa : 0.1528              
                                              
 Mcnemar's Test P-Value : &lt; 2.2e-16           
                                              
            Sensitivity : 0.11591             
            Specificity : 0.98588             
         Pos Pred Value : 0.57057             
         Neg Pred Value : 0.87324             
             Prevalence : 0.13932             
         Detection Rate : 0.01615             
   Detection Prevalence : 0.02830             
      Balanced Accuracy : 0.55089             
                                              
       'Positive' Class : Prediabetic_Diabetic
                                              </code></pre>
</div>
</div>
<p>The 3 classification tree models produced the same output. If a choice was to be made among the the three models, the most parsimonious model, Model 3 with 8 predictor variables, could be chosen.</p>
</section>
<section id="random-forest-model-1" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-model-1">Random Forest Model 1</h3>
<p>Recall that the best random forest model was model 1 using “ranger”. A table of predicted values is presented below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions using test data</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>pred_ranger <span class="ot">&lt;-</span> <span class="fu">predict</span>(rfFit_ranger_M1, <span class="at">newdata =</span> diabetesTest1, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="co">#combine predicted probabilitie with actual class labels</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>pred_ranger_actual_table <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pred_ranger, <span class="at">Actual =</span> Actual)</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>pred_ranger_actual_table <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(pred_ranger_actual_table)</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>pred_ranger_actual_table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 3
   Non_Diabetic Prediabetic_Diabetic Actual              
          &lt;dbl&gt;                &lt;dbl&gt; &lt;fct&gt;               
 1        0.584               0.416  Non_Diabetic        
 2        0.962               0.0376 Non_Diabetic        
 3        0.921               0.0789 Non_Diabetic        
 4        0.785               0.215  Non_Diabetic        
 5        0.936               0.0642 Non_Diabetic        
 6        0.989               0.0106 Non_Diabetic        
 7        0.709               0.291  Non_Diabetic        
 8        0.356               0.644  Prediabetic_Diabetic
 9        0.599               0.401  Prediabetic_Diabetic
10        0.914               0.0857 Non_Diabetic        
# ℹ 76,093 more rows</code></pre>
</div>
</div>
<p>The log loss for this model is 0.322.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate log loss for best random forest model</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="co">#use numeric_diabetes1 since it is the same test set used for logistic regression</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>ranger_log_loss <span class="ot">&lt;-</span> <span class="fu">logLoss</span>(numeric_diabetes1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>                       pred_ranger<span class="sc">$</span>Prediabetic_Diabetic)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>ranger_log_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.321795</code></pre>
</div>
</div>
<p>The confusion matrix is below. The positive predictive value appears more promising than previous models at 61.8%, but the sensitivity is lower, with only 5.9% of all prediabetic/diabetic cases being correctly identified.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions based on class</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>pred_ranger_class <span class="ot">&lt;-</span> <span class="fu">predict</span>(rfFit_ranger_M1, <span class="at">newdata =</span> diabetesTest1, </span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">type =</span> <span class="st">"raw"</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate confusion matrix</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>ranger_confusion <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_ranger_class, </span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>                                  diabetesTest1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">positive =</span> <span class="st">"Prediabetic_Diabetic"</span>)</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>ranger_confusion</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                      Reference
Prediction             Non_Diabetic Prediabetic_Diabetic
  Non_Diabetic                65116                 9981
  Prediabetic_Diabetic          384                  622
                                              
               Accuracy : 0.8638              
                 95% CI : (0.8613, 0.8662)    
    No Information Rate : 0.8607              
    P-Value [Acc &gt; NIR] : 0.006338            
                                              
                  Kappa : 0.0851              
                                              
 Mcnemar's Test P-Value : &lt; 2.2e-16           
                                              
            Sensitivity : 0.058663            
            Specificity : 0.994137            
         Pos Pred Value : 0.618290            
         Neg Pred Value : 0.867092            
             Prevalence : 0.139324            
         Detection Rate : 0.008173            
   Detection Prevalence : 0.013219            
      Balanced Accuracy : 0.526400            
                                              
       'Positive' Class : Prediabetic_Diabetic
                                              </code></pre>
</div>
</div>
<p>Simply for comparison purposes, the best random forest model using the “rf” method will be presented here as well. A table of predicted values for model 1 using “rf” is below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtain predictions using test data</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>pred_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rfFit_M1, <span class="at">newdata =</span> diabetesTest1, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co">#combine predicted probabilitie with actual class labels</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>pred_rf_actual_table <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(pred_rf, <span class="at">Actual =</span> Actual)</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>pred_rf_actual_table <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(pred_rf_actual_table)</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>pred_rf_actual_table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 76,103 × 3
   Non_Diabetic Prediabetic_Diabetic Actual              
          &lt;dbl&gt;                &lt;dbl&gt; &lt;fct&gt;               
 1        0.63                 0.37  Non_Diabetic        
 2        0.995                0.005 Non_Diabetic        
 3        0.985                0.015 Non_Diabetic        
 4        0.73                 0.27  Non_Diabetic        
 5        0.96                 0.04  Non_Diabetic        
 6        0.975                0.025 Non_Diabetic        
 7        0.715                0.285 Non_Diabetic        
 8        0.225                0.775 Prediabetic_Diabetic
 9        0.48                 0.52  Prediabetic_Diabetic
10        0.96                 0.04  Non_Diabetic        
# ℹ 76,093 more rows</code></pre>
</div>
</div>
<p>The log loss for this model on the test data is infinity, indicating that the model does not generalize well to unseen data. This usually happens when the model is overly confident in its predictions (probabilities are close to 0 or 1) and those predictions are actually incorrect.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate log loss for best random forest model</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="co">#use numeric_diabetes1 since it is the same test set used for logistic regression</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>rf_log_loss <span class="ot">&lt;-</span> <span class="fu">logLoss</span>(numeric_diabetes1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>                       pred_rf<span class="sc">$</span>Prediabetic_Diabetic)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>rf_log_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] Inf</code></pre>
</div>
</div>
<p>The confusion matrix output is below. The accuracy is slightly lower compared to the previous models at 85.96% and the predictions assigned to the Prediabetic_Diabetic class were correct 48.9% of the time, lower than the other models. Interestingly, the sensitivity is 19.1%, which is not good, but better than the other models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Obtain predictions based on class</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>pred_rf_class <span class="ot">&lt;-</span> <span class="fu">predict</span>(rfFit_M1, <span class="at">newdata =</span> diabetesTest1, </span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">type =</span> <span class="st">"raw"</span>)</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculate confusion matrix</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>rf_confusion <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_rf_class, </span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>                                  diabetesTest1<span class="sc">$</span>Diabetes_binary,</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">positive =</span> <span class="st">"Prediabetic_Diabetic"</span>)</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>rf_confusion</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                      Reference
Prediction             Non_Diabetic Prediabetic_Diabetic
  Non_Diabetic                63380                 8572
  Prediabetic_Diabetic         2120                 2031
                                              
               Accuracy : 0.8595              
                 95% CI : (0.857, 0.862)      
    No Information Rate : 0.8607              
    P-Value [Acc &gt; NIR] : 0.8256              
                                              
                  Kappa : 0.2137              
                                              
 Mcnemar's Test P-Value : &lt;2e-16              
                                              
            Sensitivity : 0.19155             
            Specificity : 0.96763             
         Pos Pred Value : 0.48928             
         Neg Pred Value : 0.88087             
             Prevalence : 0.13932             
         Detection Rate : 0.02669             
   Detection Prevalence : 0.05454             
      Balanced Accuracy : 0.57959             
                                              
       'Positive' Class : Prediabetic_Diabetic
                                              </code></pre>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Overall, the logistic regression model using all 21 predictor variables is the best model using log loss as a metric, with a log loss of 0.318. The classification trees produced a higher log loss of 0.357. The random forest model resulted in infinity log loss using the “rf” method and a log loss of 0.322 for “ranger”. The log loss of infinity indicates that the model’s predictions are unreliable due to extreme probability estimates. Looking at confusion matrices provided more information about the ability of the models to accurately predict the prediabetic/diabetic minority class. When the models predicted non-diabetics, those predictions were correct around 87% of the time. In contrast, the prediabetic/diabetic class predictions were correct 49-62% of the time, with the percentage of actual prediabetic/diabetic cases correctly identified by the models in the range of only 6-20%. These results are not unexpected given that the data is imbalanced. There are options to help balance the classes, such as undersampling and oversampling, that could improve predictions. These options are available in caret in trainControl(). Weights can also be used, which are available in the randomForest package and can be used for some methods in caret as well.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>